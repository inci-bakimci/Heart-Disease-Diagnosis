{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c8f278a-2e6e-4f0e-ad6a-e76859ff9091",
   "metadata": {},
   "source": [
    "################################################\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462dac91-66f8-424f-b5c7-9cc3d964ef78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performans Raporu ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        82\n",
      "           1       0.93      0.91      0.92       102\n",
      "\n",
      "    accuracy                           0.91       184\n",
      "   macro avg       0.91      0.91      0.91       184\n",
      "weighted avg       0.91      0.91      0.91       184\n",
      "\n",
      "ROC-AUC: 0.9555\n",
      "\n",
      "[BİLGİ] Model, Scaler ve Metadata başarıyla kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "def heart_data_prep(df):\n",
    "    \"\"\"Veri Ön İşleme ve Özellik Mühendisliği (Feature Engineering)\"\"\"\n",
    "    \n",
    "    # 1. Eksik Değer & Hatalı Girdi Operasyonları\n",
    "    df.loc[df['RestingBP'] == 0, 'RestingBP'] = df['RestingBP'].median()\n",
    "    df['Cholesterol_Is_Missing'] = (df['Cholesterol'] == 0).astype(int)\n",
    "    df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)\n",
    "    df['Cholesterol'] = df.groupby(['Sex', 'HeartDisease'])['Cholesterol'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # 2. Feature Engineering (Yeni Özellikler)\n",
    "    # Binning\n",
    "    df['Oldpeak_Bin'] = pd.cut(df['Oldpeak'], bins=[-3, 0, 1, 2, 3, 7], labels=['<0', '0-1', '1-2', '2-3', '3+'])\n",
    "    df['AgeGroup_Optimized'] = pd.cut(df['Age'], bins=[0, 45, 55, 120], labels=['Young', 'Middle', 'Senior+'])\n",
    "    \n",
    "    # Validation Features\n",
    "    df['HighChol'] = (df['Cholesterol'] > 200).astype(int)\n",
    "    df['HighResting'] = (df['RestingBP'] > 140).astype(int)\n",
    "    df['HighHR'] = (df['MaxHR'] > 130).astype(int)\n",
    "    df['MetabolicRisk'] = ((df['FastingBS'] == 1) & (df['HighChol'] == 1)).astype(int)\n",
    "    \n",
    "    # Medical Interaction Features\n",
    "    df['StressScore'] = df['Oldpeak'] * df['ExerciseAngina'].map({'Y':1, 'N':0})\n",
    "    df['RPP'] = (df['RestingBP'] * df['MaxHR']) / 100\n",
    "    df['DTS_Simulated'] = 1 - (5 * df['Oldpeak']) - (4 * df['ExerciseAngina'].map({'Y':1, 'N':0}))\n",
    "    df['HR_Efficiency'] = df['MaxHR'] / (220 - df['Age'])\n",
    "    df['Age_Oldpeak'] = df['Age'] * df['Oldpeak']\n",
    "\n",
    "    # 3. Encoding\n",
    "    ordinal_mappings = {\n",
    "        'ST_Slope': {'Up': 0, 'Flat': 1, 'Down': 2},\n",
    "        'Oldpeak_Bin': {'<0': 0, '0-1': 1, '1-2': 2, '2-3': 3, '3+': 4},\n",
    "        'AgeGroup_Optimized': {'Young': 0, 'Middle': 1, 'Senior+': 2}\n",
    "    }\n",
    "    \n",
    "    # Ordinal Mapping\n",
    "    for col, mapping in ordinal_mappings.items():\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "    # Değişkenleri yakala\n",
    "    cat_cols, num_cols, _ = grab_col_names(df)\n",
    "    cat_cols = [col for col in cat_cols if col not in ordinal_mappings.keys() and col != \"HeartDisease\"]\n",
    "\n",
    "    # One-Hot Encoding\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    # Scaling (Ölçeklendirme)\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    \n",
    "    return df, scaler, num_cols, ordinal_mappings\n",
    "\n",
    "def heart_pipeline(csv_path):\n",
    "    \"\"\"Ana Boru Hattı: Oku -> İşle -> Eğit -> Kaydet\"\"\"\n",
    "    \n",
    "    # 1. Veri Yükleme\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 2. Hazırlık\n",
    "    df_prepared, scaler, num_cols, mappings = heart_data_prep(df)\n",
    "    \n",
    "    # 3. Model Hazırlığı\n",
    "    y = df_prepared[\"HeartDisease\"]\n",
    "    X = df_prepared.drop([\"HeartDisease\"], axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "    \n",
    "    # 4. Model Eğitimi (XGBoost)\n",
    "    model_xgb = XGBClassifier(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42,\n",
    "        eval_metric='logloss', enable_categorical=True, tree_method='hist'\n",
    "    )\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Değerlendirme\n",
    "    y_pred = model_xgb.predict(X_test)\n",
    "    y_prob = model_xgb.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(\"\\n--- Model Performans Raporu ---\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.4f}\")\n",
    "    \n",
    "    # 6. KAYDETME (Paketleme)\n",
    "    joblib.dump(model_xgb, \"heart_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    \n",
    "    metadata = {\n",
    "        \"num_cols\": num_cols,\n",
    "        \"ordinal_mappings\": mappings,\n",
    "        \"features\": X.columns.tolist()\n",
    "    }\n",
    "    joblib.dump(metadata, \"pipeline_metadata.pkl\")\n",
    "    \n",
    "    print(\"\\n[BİLGİ] Model, Scaler ve Metadata başarıyla kaydedildi!\")\n",
    "\n",
    "# Çalıştırmak için:\n",
    "if __name__ == \"__main__\":\n",
    "    heart_pipeline(\"dataset/heart.csv\") # Veri yolunu kendine göre ayarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1f0fe-74cc-48f7-8711-6497da3b456f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
