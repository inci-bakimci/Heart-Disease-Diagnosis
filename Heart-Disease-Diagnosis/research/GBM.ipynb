{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa52da5-ab5c-486f-8797-f3249be2a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14729411-a71a-496d-8642-38541f27dbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GBM PİPELİNE BAŞLATILDI ---\n",
      "GBM için en iyi parametreler aranıyor (Bu işlem uzun sürebilir)...\n",
      "En İyi Parametreler: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 500, 'subsample': 0.7}\n",
      "\n",
      "[GBM Classification Report]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84        82\n",
      "           1       0.85      0.92      0.88       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.87      0.86      0.86       184\n",
      "weighted avg       0.87      0.86      0.86       184\n",
      "\n",
      "CV Accuracy: 0.8760\n",
      "CV F1-score: 0.8895\n",
      "CV ROC AUC: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MODÜL 1: DEĞİŞKEN AYRIŞTIRMA (grab_col_names)\n",
    "# ==========================================================\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 2: ÖZELLİK MÜHENDİSLİĞİ (create_new_features)\n",
    "# ==========================================================\n",
    "def create_new_features(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # 1. Klinik Skorlar ve Etkileşimler\n",
    "    df_new['RPP'] = (df_new['RestingBP'] * df_new['MaxHR']) / 100\n",
    "    \n",
    "    # ExerciseAngina'yı sayısal işleme hazırlama\n",
    "    angina_map = {'Y': 1, 'N': 0}\n",
    "    \n",
    "    # DTS: Duke Treadmill Score Simülasyonu\n",
    "    df_new['DTS_Simulated'] = 1 - (5 * df_new['Oldpeak']) - (4 * df_new['ExerciseAngina'].map(angina_map))\n",
    "    \n",
    "    df_new['HR_Efficiency'] = df_new['MaxHR'] / (220 - df_new['Age'])\n",
    "    df_new['Age_Oldpeak'] = df_new['Age'] * df_new['Oldpeak']\n",
    "\n",
    "    # 2. Risk Grupları ve Kategorizasyon\n",
    "    df_new['HighChol'] = (df_new['Cholesterol'] > 200).astype(int)\n",
    "    \n",
    "    # AgeGroup_Optimized: Yaşa dayalı risk segmentasyonu\n",
    "    df_new['AgeGroup_Optimized'] = pd.cut(\n",
    "        df_new['Age'], \n",
    "        bins=[0, 45, 55, 120], \n",
    "        labels=['Young', 'Middle', 'Senior+']\n",
    "    )\n",
    "    \n",
    "    df_new['MetabolicRisk'] = ((df_new['FastingBS'] == 1) & (df_new['HighChol'] == 1)).astype(int)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 3: VERİ ÖN İŞLEME (Preprocessing & Leakage Protection)\n",
    "# ==========================================================\n",
    "def heart_data_prep(X_train, X_test):\n",
    "    # Train ve Test kopyaları üzerinden işlem yapma\n",
    "    X_train_prep = X_train.copy()\n",
    "    X_test_prep = X_test.copy()\n",
    "\n",
    "    # 1. Hatalı/Eksik Veri İşaretleme\n",
    "    for df in [X_train_prep, X_test_prep]:\n",
    "        # Kolesterol 0 değerlerini NaN yap\n",
    "        df['Cholesterol_Is_Missing'] = (df['Cholesterol'] == 0).astype(int)\n",
    "        df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)\n",
    "        # Kan Basıncı 0 değerlerini NaN yap\n",
    "        df['RestingBP'] = df['RestingBP'].replace(0, np.nan)\n",
    "\n",
    "    # 2. Sızıntısız Doldurma (Imputation)\n",
    "    # Sadece TRAIN setinden istatistikleri alıyoruz\n",
    "    chol_medians = X_train_prep.groupby('Sex')['Cholesterol'].median()\n",
    "    bp_median = X_train_prep['RestingBP'].median()\n",
    "\n",
    "    # Train ve Test setlerini Train'den gelen bilgiyle doldurma\n",
    "    for gender in ['M', 'F']:\n",
    "        X_train_prep.loc[(X_train_prep['Sex'] == gender) & (X_train_prep['Cholesterol'].isna()), 'Cholesterol'] = chol_medians[gender]\n",
    "        X_test_prep.loc[(X_test_prep['Sex'] == gender) & (X_test_prep['Cholesterol'].isna()), 'Cholesterol'] = chol_medians[gender]\n",
    "\n",
    "    X_train_prep['RestingBP'] = X_train_prep['RestingBP'].fillna(bp_median)\n",
    "    X_test_prep['RestingBP'] = X_test_prep['RestingBP'].fillna(bp_median)\n",
    "\n",
    "    # 3. Encoding İşlemi\n",
    "    # Önce kolonları belirle\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(X_train_prep)\n",
    "    \n",
    "    # One-Hot Encoding (Dummies)\n",
    "    X_train_prep = pd.get_dummies(X_train_prep, columns=cat_cols, drop_first=True)\n",
    "    X_test_prep = pd.get_dummies(X_test_prep, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Kolon eşitleme (Train'de olup Test'te olmayan kolonları 0 ile doldur)\n",
    "    X_test_prep = X_test_prep.reindex(columns=X_train_prep.columns, fill_value=0)\n",
    "\n",
    "    return X_train_prep, X_test_prep\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 4: FINAL PIPELINE\n",
    "# ==========================================================\n",
    "def run_gbm_pipeline(df, target=\"HeartDisease\"):\n",
    "    print(\"\\n--- GBM PİPELİNE BAŞLATILDI ---\")\n",
    "    \n",
    "    # 1. Özellik Mühendisliği (Modül 2)\n",
    "    df_enriched = create_new_features(df)\n",
    "    \n",
    "    # 2. Train-Test Ayırma\n",
    "    y = df_enriched[target]\n",
    "    X = df_enriched.drop(target, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=17)\n",
    "    \n",
    "    # 3. Ön İşleme (Modül 3)\n",
    "    X_train_prep, X_test_prep = heart_data_prep(X_train, X_test)\n",
    "    \n",
    "    # 4. Hiperparametre Optimizasyonu (Grid Search)\n",
    "    gbm_model = GradientBoostingClassifier(random_state=17)\n",
    "    \n",
    "    # GBM'e özel learning_rate ve subsample parametreleri eklendi\n",
    "    gbm_params = {\"learning_rate\": [0.01, 0.1],\n",
    "                  \"max_depth\": [3, 5, 8],\n",
    "                  \"n_estimators\": [100, 500, 1000],\n",
    "                  \"subsample\": [1, 0.5, 0.7]}\n",
    "    \n",
    "    print(\"GBM için en iyi parametreler aranıyor (Bu işlem uzun sürebilir)...\")\n",
    "    gbm_best_grid = GridSearchCV(gbm_model, gbm_params, cv=5, n_jobs=-1, verbose=0).fit(X_train_prep, y_train)\n",
    "    print(f\"En İyi Parametreler: {gbm_best_grid.best_params_}\")\n",
    "    \n",
    "    # 5. Final Model ve Değerlendirme\n",
    "    gbm_final = gbm_model.set_params(**gbm_best_grid.best_params_, random_state=17).fit(X_train_prep, y_train)\n",
    "    y_pred = gbm_final.predict(X_test_prep)\n",
    "    \n",
    "    print(\"\\n[GBM Classification Report]:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # 6. Çapraz Doğrulama (Cross Validation)\n",
    "    cv_results = cross_validate(gbm_final, X_train_prep, y_train, cv=5, \n",
    "                                 scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
    "    \n",
    "    print(f\"CV Accuracy: {cv_results['test_accuracy'].mean():.4f}\")\n",
    "    print(f\"CV F1-score: {cv_results['test_f1'].mean():.4f}\")\n",
    "    print(f\"CV ROC AUC: {cv_results['test_roc_auc'].mean():.4f}\")\n",
    "    \n",
    "    return gbm_final\n",
    "\n",
    "# ÇALIŞTIRMA:\n",
    "def load():\n",
    "    data = pd.read_csv(\"dataset/heart.csv\")\n",
    "    return data\n",
    "df = load()\n",
    "gbm_final_model = run_gbm_pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31990c40-11d1-4d28-948b-612597359bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
