{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f9f441-85ec-498e-a2a1-d915813436c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz, export_text\n",
    "from sklearn.model_selection import GridSearchCV, validation_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.width', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c56d0a-306e-488a-8e72-8648e49f3a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ÖZEL PARAMETRELİ XGBOOST BAŞLATILDI ---\n",
      "\n",
      "[XGBoost Özel Sonuçlar]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86        82\n",
      "           1       0.88      0.89      0.89       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.87      0.87      0.87       184\n",
      "weighted avg       0.87      0.88      0.87       184\n",
      "\n",
      "CV Accuracy: 0.8637\n",
      "CV ROC AUC: 0.9259\n",
      "CV F1-score: 0.8769\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# MODÜL 1: DEĞİŞKEN AYRIŞTIRMA (grab_col_names)\n",
    "# ==========================================================\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 2: ÖZELLİK MÜHENDİSLİĞİ (create_new_features)\n",
    "# ==========================================================\n",
    "def create_new_features(df):\n",
    "    df_new = df.copy()\n",
    "    \n",
    "    # 1. Klinik Skorlar ve Etkileşimler\n",
    "    df_new['RPP'] = (df_new['RestingBP'] * df_new['MaxHR']) / 100\n",
    "    \n",
    "    # ExerciseAngina'yı sayısal işleme hazırlama\n",
    "    angina_map = {'Y': 1, 'N': 0}\n",
    "    \n",
    "    # DTS: Duke Treadmill Score Simülasyonu\n",
    "    df_new['DTS_Simulated'] = 1 - (5 * df_new['Oldpeak']) - (4 * df_new['ExerciseAngina'].map(angina_map))\n",
    "    \n",
    "    df_new['HR_Efficiency'] = df_new['MaxHR'] / (220 - df_new['Age'])\n",
    "    df_new['Age_Oldpeak'] = df_new['Age'] * df_new['Oldpeak']\n",
    "\n",
    "    # 2. Risk Grupları ve Kategorizasyon\n",
    "    df_new['HighChol'] = (df_new['Cholesterol'] > 200).astype(int)\n",
    "    \n",
    "    # AgeGroup_Optimized: Yaşa dayalı risk segmentasyonu\n",
    "    df_new['AgeGroup_Optimized'] = pd.cut(\n",
    "        df_new['Age'], \n",
    "        bins=[0, 45, 55, 120], \n",
    "        labels=['Young', 'Middle', 'Senior+']\n",
    "    )\n",
    "    \n",
    "    df_new['MetabolicRisk'] = ((df_new['FastingBS'] == 1) & (df_new['HighChol'] == 1)).astype(int)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 3: VERİ ÖN İŞLEME (Preprocessing & Leakage Protection)\n",
    "# ==========================================================\n",
    "def heart_data_prep(X_train, X_test):\n",
    "    # Train ve Test kopyaları üzerinden işlem yapma\n",
    "    X_train_prep = X_train.copy()\n",
    "    X_test_prep = X_test.copy()\n",
    "\n",
    "    # 1. Hatalı/Eksik Veri İşaretleme\n",
    "    for df in [X_train_prep, X_test_prep]:\n",
    "        # Kolesterol 0 değerlerini NaN yap\n",
    "        df['Cholesterol_Is_Missing'] = (df['Cholesterol'] == 0).astype(int)\n",
    "        df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)\n",
    "        # Kan Basıncı 0 değerlerini NaN yap\n",
    "        df['RestingBP'] = df['RestingBP'].replace(0, np.nan)\n",
    "\n",
    "    # 2. Sızıntısız Doldurma (Imputation)\n",
    "    # Sadece TRAIN setinden istatistikleri alıyoruz\n",
    "    chol_medians = X_train_prep.groupby('Sex')['Cholesterol'].median()\n",
    "    bp_median = X_train_prep['RestingBP'].median()\n",
    "\n",
    "    # Train ve Test setlerini Train'den gelen bilgiyle doldurma\n",
    "    for gender in ['M', 'F']:\n",
    "        X_train_prep.loc[(X_train_prep['Sex'] == gender) & (X_train_prep['Cholesterol'].isna()), 'Cholesterol'] = chol_medians[gender]\n",
    "        X_test_prep.loc[(X_test_prep['Sex'] == gender) & (X_test_prep['Cholesterol'].isna()), 'Cholesterol'] = chol_medians[gender]\n",
    "\n",
    "    X_train_prep['RestingBP'] = X_train_prep['RestingBP'].fillna(bp_median)\n",
    "    X_test_prep['RestingBP'] = X_test_prep['RestingBP'].fillna(bp_median)\n",
    "\n",
    "    # 3. Encoding İşlemi\n",
    "    # Önce kolonları belirle\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(X_train_prep)\n",
    "    \n",
    "    # One-Hot Encoding (Dummies)\n",
    "    X_train_prep = pd.get_dummies(X_train_prep, columns=cat_cols, drop_first=True)\n",
    "    X_test_prep = pd.get_dummies(X_test_prep, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # Kolon eşitleme (Train'de olup Test'te olmayan kolonları 0 ile doldur)\n",
    "    X_test_prep = X_test_prep.reindex(columns=X_train_prep.columns, fill_value=0)\n",
    "\n",
    "    return X_train_prep, X_test_prep\n",
    "\n",
    "# ==========================================================\n",
    "# MODÜL 4: FINAL PIPELINE\n",
    "# ==========================================================\n",
    "def run_custom_xgboost(df, target=\"HeartDisease\"):\n",
    "    print(\"\\n--- ÖZEL PARAMETRELİ XGBOOST BAŞLATILDI ---\")\n",
    "    \n",
    "    # 1. Özellik Mühendisliği ve Hazırlık\n",
    "    df_enriched = create_new_features(df)\n",
    "    y = df_enriched[target]\n",
    "    X = df_enriched.drop(target, axis=1)\n",
    "    \n",
    "    # Veri setini ayırma\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "    \n",
    "    # 2. Ön İşleme Hattı\n",
    "    X_train_prep, X_test_prep = heart_data_prep(X_train, X_test)\n",
    "    \n",
    "    # 3. Model Kurulumu (Senin belirlediğin parametreler)\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=90,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    # 4. Eğitim ve Çapraz Doğrulama\n",
    "    model.fit(X_train_prep, y_train)\n",
    "    \n",
    "    # 5. Sonuçların Raporlanması\n",
    "    y_pred = model.predict(X_test_prep)\n",
    "    print(\"\\n[XGBoost Özel Sonuçlar]:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cv_results = cross_validate(model, X_train_prep, y_train, cv=5, scoring=[\"accuracy\", \"roc_auc\", \"f1\"])\n",
    "    print(f\"CV Accuracy: {cv_results['test_accuracy'].mean():.4f}\")\n",
    "    print(f\"CV ROC AUC: {cv_results['test_roc_auc'].mean():.4f}\")\n",
    "    print(f\"CV F1-score: {cv_results['test_f1'].mean():.4f}\")\n",
    "    \n",
    "    # 6. Kayıt\n",
    "    #joblib.dump(model, \"custom_xgboost_model.pkl\")\n",
    "    return model\n",
    "\n",
    "# ÇALIŞTIRMA:\n",
    "def load():\n",
    "    data = pd.read_csv(\"dataset/heart.csv\")\n",
    "    return data\n",
    "df = load()\n",
    "custom_xgb = run_custom_xgboost(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e67ba5-f203-470c-8a03-fa627e3f8527",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
