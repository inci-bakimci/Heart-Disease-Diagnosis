{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2941fb-efe3-4851-a80a-aceefa88252e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.6.1\n",
      "Uninstalling scikit-learn-1.6.1:\n",
      "  Successfully uninstalled scikit-learn-1.6.1\n",
      "Collecting scikit-learn==1.2.2\n",
      "  Using cached scikit_learn-1.2.2-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\victus\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (3.6.0)\n",
      "Using cached scikit_learn-1.2.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall scikit-learn -y\n",
    "!pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f854271-ddd4-4ae9-8f6c-c6f45ebd356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Models....\n",
      "roc_auc: 0.8973 (LR) \n",
      "roc_auc: 0.8772 (KNN) \n",
      "roc_auc: 0.8985 (SVC) \n",
      "roc_auc: 0.7683 (CART) \n",
      "roc_auc: 0.9086 (RF) \n",
      "roc_auc: 0.8882 (Adaboost) \n",
      "roc_auc: 0.9015 (GBM) \n",
      "roc_auc: 0.9101 (XGBoost) \n",
      "roc_auc: 0.9029 (LightGBM) \n",
      "\n",
      "Hyperparameter Optimization....\n",
      "########## KNN ##########\n",
      "roc_auc (After GS): 0.8772\n",
      "########## CART ##########\n",
      "roc_auc (After GS): 0.8097\n",
      "########## RF ##########\n",
      "roc_auc (After GS): 0.905\n",
      "########## XGBoost ##########\n",
      "roc_auc (After GS): 0.9007\n",
      "########## LightGBM ##########\n",
      "roc_auc (After GS): 0.9075\n",
      "\n",
      "Voting Classifier...\n",
      "Accuracy: 0.8399\n",
      "F1Score: 0.8557\n",
      "ROC_AUC: 0.908\n",
      "\n",
      "[BİLGİ] Tüm süreç tamamlandı ve modeller rafa kaldırıldı!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "################################################\n",
    "# 1. Helper Functions (Yardımcı Fonksiyonlar)\n",
    "################################################\n",
    "\n",
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "def heart_data_prep(df):\n",
    "    \"\"\"Veri Ön İşleme ve Özellik Mühendisliği\"\"\"\n",
    "    # Eksik/Hatalı Değerler\n",
    "    df.loc[df['RestingBP'] == 0, 'RestingBP'] = df['RestingBP'].median()\n",
    "    df['Cholesterol_Is_Missing'] = (df['Cholesterol'] == 0).astype(int)\n",
    "    df['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)\n",
    "    df['Cholesterol'] = df.groupby(['Sex', 'HeartDisease'])['Cholesterol'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    # Feature Engineering\n",
    "    df['Oldpeak_Bin'] = pd.cut(df['Oldpeak'], bins=[-3, 0, 1, 2, 3, 7], labels=['<0', '0-1', '1-2', '2-3', '3+'])\n",
    "    df['AgeGroup_Optimized'] = pd.cut(df['Age'], bins=[0, 45, 55, 120], labels=['Young', 'Middle', 'Senior+'])\n",
    "    \n",
    "    # Yeni Özellikler\n",
    "    df['HighChol'] = (df['Cholesterol'] > 200).astype(int)\n",
    "    df['MetabolicRisk'] = ((df['FastingBS'] == 1) & (df['HighChol'] == 1)).astype(int)\n",
    "    df['StressScore'] = df['Oldpeak'] * df['ExerciseAngina'].map({'Y':1, 'N':0})\n",
    "    df['DTS_Simulated'] = 1 - (5 * df['Oldpeak']) - (4 * df['ExerciseAngina'].map({'Y':1, 'N':0}))\n",
    "    df['Age_Oldpeak'] = df['Age'] * df['Oldpeak']\n",
    "    df['RPP'] = (df['RestingBP'] * df['MaxHR']) / 100\n",
    "\n",
    "    # Encoding\n",
    "    ordinal_mappings = {\n",
    "        'ST_Slope': {'Up': 0, 'Flat': 1, 'Down': 2},\n",
    "        'Oldpeak_Bin': {'<0': 0, '0-1': 1, '1-2': 2, '2-3': 3, '3+': 4},\n",
    "        'AgeGroup_Optimized': {'Young': 0, 'Middle': 1, 'Senior+': 2}\n",
    "    }\n",
    "    for col, mapping in ordinal_mappings.items():\n",
    "        df[col] = df[col].map(mapping)\n",
    "\n",
    "    cat_cols, num_cols, _ = grab_col_names(df)\n",
    "    cat_cols = [col for col in cat_cols if col not in ordinal_mappings.keys() and col != \"HeartDisease\"]\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "    return df, scaler, num_cols, ordinal_mappings\n",
    "\n",
    "################################################\n",
    "# 2. Modeling Functions (Modelleme)\n",
    "################################################\n",
    "\n",
    "def base_models(X, y, scoring=\"roc_auc\"):\n",
    "    print(\"Base Models....\")\n",
    "    classifiers = [('LR', LogisticRegression()),\n",
    "                   ('KNN', KNeighborsClassifier()),\n",
    "                   (\"SVC\", SVC()),\n",
    "                   (\"CART\", DecisionTreeClassifier()),\n",
    "                   (\"RF\", RandomForestClassifier()),\n",
    "                   ('Adaboost', AdaBoostClassifier()),\n",
    "                   ('GBM', GradientBoostingClassifier()),\n",
    "                   #Düzeltildi\n",
    "                   ('XGBoost', XGBClassifier(eval_metric='logloss', enable_categorical=True, tree_method='hist')),\n",
    "                   ('LightGBM', LGBMClassifier(verbose=-1))]\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
    "def base_models(X, y, scoring=\"roc_auc\"):\n",
    "    print(\"Base Models....\")\n",
    "    classifiers = [('LR', LogisticRegression()),\n",
    "                   ('KNN', KNeighborsClassifier()),\n",
    "                   (\"SVC\", SVC()),\n",
    "                   (\"CART\", DecisionTreeClassifier()),\n",
    "                   (\"RF\", RandomForestClassifier()),\n",
    "                   ('Adaboost', AdaBoostClassifier()),\n",
    "                   ('GBM', GradientBoostingClassifier()),\n",
    "                   # --- DÜZELTME BURADA ---\n",
    "                   ('XGBoost', XGBClassifier(eval_metric='logloss', enable_categorical=True, tree_method='hist')),\n",
    "                   ('LightGBM', LGBMClassifier(verbose=-1, enable_categorical=True))]\n",
    "\n",
    "    for name, classifier in classifiers:\n",
    "        cv_results = cross_validate(classifier, X, y, cv=3, scoring=scoring)\n",
    "        print(f\"{scoring}: {round(cv_results['test_score'].mean(), 4)} ({name}) \")\n",
    "\n",
    "def hyperparameter_optimization(X, y, cv=3, scoring=\"roc_auc\"):\n",
    "    print(\"\\nHyperparameter Optimization....\")\n",
    "    \n",
    "    knn_params = {\"n_neighbors\": range(2, 20)}\n",
    "    cart_params = {'max_depth': range(1, 10), \"min_samples_split\": range(2, 10)}\n",
    "    rf_params = {\"max_depth\": [8, 15, None], \"max_features\": [5, 7, \"sqrt\"], \"n_estimators\": [100, 200]}\n",
    "    \n",
    "    # --- DÜZELTME BURADA ---\n",
    "    xgboost_params = {\"learning_rate\": [0.1, 0.01], \"max_depth\": [5, 8], \"n_estimators\": [100, 200]}\n",
    "    lightgbm_params = {\"learning_rate\": [0.01, 0.1], \"n_estimators\": [300, 500]}\n",
    "\n",
    "    classifiers = [('KNN', KNeighborsClassifier(), knn_params),\n",
    "                   (\"CART\", DecisionTreeClassifier(), cart_params),\n",
    "                   (\"RF\", RandomForestClassifier(), rf_params),\n",
    "                   # XGBoost ve LightGBM nesnelerine parametreleri ekledik\n",
    "                   ('XGBoost', XGBClassifier(eval_metric='logloss', enable_categorical=True, tree_method='hist'), xgboost_params),\n",
    "                   ('LightGBM', LGBMClassifier(verbose=-1, enable_categorical=True), lightgbm_params)]\n",
    "\n",
    "    best_models = {}\n",
    "    for name, classifier, params in classifiers:\n",
    "        print(f\"########## {name} ##########\")\n",
    "        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)\n",
    "        final_model = classifier.set_params(**gs_best.best_params_)\n",
    "        \n",
    "        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)\n",
    "        print(f\"{scoring} (After GS): {round(cv_results['test_score'].mean(), 4)}\")\n",
    "        best_models[name] = final_model\n",
    "    return best_models\n",
    "def voting_classifier(best_models, X, y):\n",
    "    print(\"\\nVoting Classifier...\")\n",
    "    voting_clf = VotingClassifier(estimators=[('XGBoost', best_models[\"XGBoost\"]), \n",
    "                                              ('RF', best_models[\"RF\"]),\n",
    "                                              ('LightGBM', best_models[\"LightGBM\"])],\n",
    "                                  voting='soft').fit(X, y)\n",
    "    \n",
    "    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n",
    "    print(f\"Accuracy: {round(cv_results['test_accuracy'].mean(), 4)}\")\n",
    "    print(f\"F1Score: {round(cv_results['test_f1'].mean(), 4)}\")\n",
    "    print(f\"ROC_AUC: {round(cv_results['test_roc_auc'].mean(), 4)}\")\n",
    "    return voting_clf\n",
    "\n",
    "################################################\n",
    "# 3. Main Pipeline\n",
    "################################################\n",
    "\n",
    "def main():\n",
    "    # 1. Veri Yükleme (Dosya yoluna dikkat!)\n",
    "    df = pd.read_csv(\"dataset/heart.csv\") \n",
    "    \n",
    "    # 2. Hazırlık\n",
    "    df_prepared, scaler, num_cols, mappings = heart_data_prep(df)\n",
    "    y = df_prepared[\"HeartDisease\"]\n",
    "    X = df_prepared.drop([\"HeartDisease\"], axis=1)\n",
    "\n",
    "    # 3. Temel Modeller\n",
    "    base_models(X, y)\n",
    "\n",
    "    # 4. Hiperparametre Optimizasyonu\n",
    "    best_models = hyperparameter_optimization(X, y)\n",
    "\n",
    "    # 5. Ensemble Modeli\n",
    "    voting_clf = voting_classifier(best_models, X, y)\n",
    "\n",
    "    # 6. Kaydetme\n",
    "    joblib.dump(voting_clf, \"heart_voting_model.pkl\")\n",
    "    joblib.dump(scaler, \"scaler.pkl\")\n",
    "    metadata = {\"num_cols\": num_cols, \"ordinal_mappings\": mappings, \"features\": X.columns.tolist()}\n",
    "    joblib.dump(metadata, \"pipeline_metadata.pkl\")\n",
    "    \n",
    "    print(\"\\n[BİLGİ] Tüm süreç tamamlandı ve modeller rafa kaldırıldı!\")\n",
    "    return voting_clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4d3eaf-9f4d-43bb-bb9c-2765292ee4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606f3fb1-7ba4-438e-a154-2209ade9478c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
